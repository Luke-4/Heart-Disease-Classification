{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9801cf77",
   "metadata": {},
   "source": [
    "# import libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6964adcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RepeatedEditedNearestNeighbours\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924717ce",
   "metadata": {},
   "source": [
    "# import the dataset and balance labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b34b4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../heart_disease/heart_disease.csv')\n",
    "#df.isnull().sum() #check for null values \n",
    "#df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "474dc98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop (labels = ['HeartDiseaseorAttack'], axis =1)\n",
    "y = df['HeartDiseaseorAttack']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1012cc9",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e6c66df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal number of features: 17\n",
      "Best features: Index(['HighBP', 'HighChol', 'BMI', 'Smoker', 'Stroke', 'Diabetes',\n",
      "       'PhysActivity', 'Fruits', 'Veggies', 'GenHlth', 'MentHlth', 'PhysHlth',\n",
      "       'DiffWalk', 'Sex', 'Age', 'Education', 'Income'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "#balanced_accuracy, or f1_weighted\n",
    "rfecv = RFECV(estimator= DecisionTreeClassifier(), step = 1, cv = 10, scoring=\"balanced_accuracy\", n_jobs=-1)\n",
    "rfecv = rfecv.fit(X, y)\n",
    "\n",
    "print(\"The optimal number of features:\", rfecv.n_features_)\n",
    "print(\"Best features:\", X.columns[rfecv.support_])\n",
    "\n",
    "\n",
    "X_new = rfecv.transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57903dfa",
   "metadata": {},
   "source": [
    "# Resampling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4ed72ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y balanced Counter({0.0: 96314, 1.0: 32189})\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train , y_test = train_test_split(X_new,y,test_size=0.3, random_state=1234) \n",
    "\n",
    "over=  RandomOverSampler(sampling_strategy=0.2)\n",
    "under= RepeatedEditedNearestNeighbours(sampling_strategy='majority', max_iter=100,n_neighbors=7, kind_sel='all', n_jobs=-1)\n",
    "\n",
    "X_balanced, y_balanced = over.fit_resample(X_train, y_train)\n",
    "X_balanced, y_balanced = under.fit_resample(X_balanced, y_balanced)\n",
    "\n",
    "print(f'Y balanced {Counter(y_balanced)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cf9f1a",
   "metadata": {},
   "source": [
    "# Scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "640c3299",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_balanced)\n",
    "\n",
    "scaleddata=scaler.transform(X_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f82c3a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(scaleddata.dtype.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9285a5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.55198945 5.30866781]\n"
     ]
    }
   ],
   "source": [
    "# calculate heuristic class weighting\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "weighting = compute_class_weight(class_weight='balanced', classes=[0,1], y=y)\n",
    "print(weighting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec041cb",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b425e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lucas\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "2100 fits failed out of a total of 3500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1400 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\lucas\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\lucas\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\lucas\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 55, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "700 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\lucas\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\lucas\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\lucas\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 48, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got newton-cholesky.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\lucas\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan 0.95748996\n",
      " 0.95748993        nan 0.95748999 0.95748988        nan        nan\n",
      "        nan        nan        nan 0.95753099 0.95753098        nan\n",
      " 0.95753109 0.95753085        nan        nan        nan        nan\n",
      "        nan 0.9573692  0.95736926        nan 0.95736927 0.91758892\n",
      "        nan        nan        nan        nan        nan 0.95768192\n",
      " 0.95768202        nan 0.95768187 0.95768185        nan        nan\n",
      "        nan        nan        nan 0.95757477 0.95757486        nan\n",
      " 0.95757476 0.95757473        nan        nan        nan        nan\n",
      "        nan 0.95758546 0.95758544        nan 0.95758534 0.95758543\n",
      "        nan        nan        nan        nan        nan 0.95650003\n",
      " 0.95650016        nan 0.95649982 0.93425649        nan        nan\n",
      "        nan        nan        nan 0.95767388 0.95767393        nan\n",
      " 0.95767408 0.95767403        nan        nan        nan        nan\n",
      "        nan 0.9576587  0.95765866        nan 0.95765872 0.95765871\n",
      "        nan        nan        nan        nan        nan 0.95722573\n",
      " 0.95722571        nan 0.91501015 0.92132881        nan        nan\n",
      "        nan        nan        nan 0.95763182 0.95763183        nan\n",
      " 0.957632   0.95763173        nan        nan        nan        nan\n",
      "        nan 0.95789047 0.9578904         nan 0.95789038 0.95789025\n",
      "        nan        nan        nan        nan        nan 0.95766928\n",
      " 0.95766926        nan 0.95766926 0.95766928        nan        nan\n",
      "        nan        nan        nan 0.95644914 0.95644921        nan\n",
      " 0.95588813 0.94078598        nan        nan        nan        nan\n",
      "        nan 0.9576857  0.95768581        nan 0.95768578 0.95768584\n",
      "        nan        nan        nan        nan        nan 0.95761188\n",
      " 0.95761196        nan 0.95761202 0.95761183        nan        nan\n",
      "        nan        nan        nan 0.95719424 0.95719419        nan\n",
      " 0.91798809 0.92255415        nan        nan        nan        nan\n",
      "        nan 0.95760299 0.95760291        nan 0.9576029  0.95760307\n",
      "        nan        nan        nan        nan        nan 0.95788975\n",
      " 0.95788976        nan 0.95788994 0.95788983        nan        nan\n",
      "        nan        nan        nan 0.95767564 0.95767569        nan\n",
      " 0.95767557 0.95767552        nan        nan        nan        nan\n",
      "        nan 0.95644157 0.95644175        nan 0.89729954 0.92293404\n",
      "        nan        nan        nan        nan        nan 0.95768707\n",
      " 0.95768704        nan 0.95768687 0.95768701        nan        nan\n",
      "        nan        nan        nan 0.95760629 0.95760628        nan\n",
      " 0.95760642 0.95760612        nan        nan        nan        nan\n",
      "        nan 0.9571908  0.95719082        nan 0.91970561 0.92014494\n",
      "        nan        nan        nan        nan        nan 0.95759954\n",
      " 0.95759954        nan 0.95759953 0.95759971        nan        nan\n",
      "        nan        nan        nan 0.95788971 0.95788981        nan\n",
      " 0.95788986 0.95788971        nan        nan        nan        nan\n",
      "        nan 0.95767603 0.95767609        nan 0.95767605 0.95767611\n",
      "        nan        nan        nan        nan        nan 0.95644061\n",
      " 0.95644056        nan 0.89985177 0.91272554        nan        nan\n",
      "        nan        nan        nan 0.95768717 0.95768718        nan\n",
      " 0.95768712 0.95768708        nan        nan        nan        nan\n",
      "        nan 0.95760578 0.95760579        nan 0.95760583 0.9576058\n",
      "        nan        nan        nan        nan        nan 0.95719032\n",
      " 0.95719037        nan 0.89771616 0.92613769        nan        nan\n",
      "        nan        nan        nan 0.95759918 0.95759921        nan\n",
      " 0.95759951 0.95759923        nan        nan        nan        nan\n",
      "        nan 0.9578897  0.95788962        nan 0.95788967 0.9578898\n",
      "        nan        nan        nan        nan        nan 0.95767612\n",
      " 0.95767618        nan 0.95767628 0.95767616        nan        nan\n",
      "        nan        nan        nan 0.95644051 0.95644054        nan\n",
      " 0.89801803 0.89388912]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best leaf_size: l2\n",
      "Best p: 0.01\n",
      "Best n_neighbors: {0: 1, 1: 1}\n",
      "Best n_neighbors: lbfgs\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#hyperparameter tunning\n",
    "#grid search \n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "penalty=[\"None\", \"l2\"]\n",
    "C = [0.001, 0.01, 0.1, 1, 10]\n",
    "class_weight=[{0:0.55,1:5.3},{0:5.3,1:0.55},{0:100,1:1}, {0:10,1:1}, {0:1,1:1}, {0:1,1:10}, {0:1,1:100}]\n",
    "solver= [\"lbfgs\", \"newton-cg\", \"newton-cholesky\", \"sag\", \"saga\"]\n",
    "\n",
    "hyperparameters=dict(penalty=penalty, C=C, class_weight=class_weight, solver=solver )\n",
    "\n",
    "model=LogisticRegression()\n",
    "\n",
    "param_search=GridSearchCV(model,hyperparameters,cv=10, scoring=\"roc_auc\", n_jobs=-1)\n",
    "\n",
    "#knn_param_search.fit(X_train,y_train)\n",
    "\n",
    "best_model = param_search.fit(scaleddata,y_balanced)\n",
    "\n",
    "print('Best leaf_size:', best_model.best_estimator_.get_params()['penalty'])\n",
    "print('Best p:', best_model.best_estimator_.get_params()['C'])\n",
    "print('Best n_neighbors:', best_model.best_estimator_.get_params()['class_weight'])\n",
    "print('Best n_neighbors:', best_model.best_estimator_.get_params()['solver'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55656d8",
   "metadata": {},
   "source": [
    "# Decision Tree check training score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa0d5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#hyperparameter tunning\n",
    "#grid search \n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "criterion =[\"None\", \"l2\"]\n",
    "max_depth  = [0.001, 0.01, 0.1, 1, 10]\n",
    "max_leaf_nodes =[{0:0.55,1:5.3},{0:5.3,1:0.55},{0:100,1:1}, {0:10,1:1}, {0:1,1:1}, {0:1,1:10}, {0:1,1:100}]\n",
    "min_samples_split = [\"lbfgs\", \"newton-cg\", \"newton-cholesky\", \"sag\", \"saga\"]\n",
    "min_samples_leaf \n",
    "\n",
    "hyperparameters=dict(penalty=penalty, C=C, class_weight=class_weight, solver=solver )\n",
    "\n",
    "model=DecisionTreeClassifier()\n",
    "\n",
    "param_search=GridSearchCV(model,hyperparameters,cv=10, scoring=\"roc_auc\", n_jobs=-1)\n",
    "\n",
    "#knn_param_search.fit(X_train,y_train)\n",
    "\n",
    "best_model = param_search.fit(scaleddata,y_balanced)\n",
    "\n",
    "print('Best leaf_size:', best_model.best_estimator_.get_params()['penalty'])\n",
    "print('Best p:', best_model.best_estimator_.get_params()['C'])\n",
    "print('Best n_neighbors:', best_model.best_estimator_.get_params()['class_weight'])\n",
    "print('Best n_neighbors:', best_model.best_estimator_.get_params()['solver'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cf883c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "        0.0       0.93      0.76      0.47      0.84      0.60      0.37     68840\n",
      "        1.0       0.17      0.47      0.76      0.25      0.60      0.35      7264\n",
      "\n",
      "avg / total       0.86      0.73      0.50      0.78      0.60      0.37     76104\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model2= DecisionTreeClassifier()\n",
    "\n",
    "pipeline = Pipeline([('StandardScaler', StandardScaler()), ('over', over), ('under', under), ('model2', model2)])\n",
    "\n",
    "pipeline.fit(X_train, y_train) \n",
    "\n",
    "y_hat = pipeline.predict(X_test)\n",
    "print(classification_report_imbalanced(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479c1b35",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6baf5cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "X_train, X_test, y_train , y_test = train_test_split(X_new,y,test_size=0.3, random_state=0) \n",
    "\n",
    "model2= SVC(random_state=0)\n",
    "\n",
    "pipeline = Pipeline([('StandardScaler', StandardScaler()), ('over', over), ('under', under), ('model2', model2)])\n",
    "\n",
    "\n",
    "pipeline.fit(X_train, y_train) \n",
    "\n",
    "y_hat = pipeline.predict(X_test)\n",
    "print(classification_report_imbalanced(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d08a2e8",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c5f9ae15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "        0.0       0.96      0.76      0.69      0.85      0.72      0.52     68840\n",
      "        1.0       0.23      0.69      0.76      0.34      0.72      0.52      7264\n",
      "\n",
      "avg / total       0.89      0.75      0.70      0.80      0.72      0.52     76104\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "\n",
    "X_train, X_test, y_train , y_test = train_test_split(X_new,y,test_size=0.3, random_state=0) \n",
    "\n",
    "model2= KNeighborsClassifier(n_neighbors=5, n_jobs= -1)\n",
    "\n",
    "pipeline = Pipeline([('StandardScaler', StandardScaler()), ('over', over), ('under', under), ('model2', model2)])\n",
    "\n",
    "\n",
    "pipeline.fit(X_train, y_train) \n",
    "\n",
    "y_hat = pipeline.predict(X_test)\n",
    "print(classification_report_imbalanced(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e447ebe5",
   "metadata": {},
   "source": [
    "# NB classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d7c0ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "        0.0       0.96      0.76      0.72      0.85      0.74      0.55     68840\n",
      "        1.0       0.24      0.72      0.76      0.36      0.74      0.54      7264\n",
      "\n",
      "avg / total       0.89      0.76      0.72      0.80      0.74      0.55     76104\n",
      "\n",
      "[[52552 16288]\n",
      " [ 2062  5202]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB\n",
    "    \n",
    "X_train, X_test, y_train , y_test = train_test_split(X_new,y,test_size=0.3, random_state=0) \n",
    "\n",
    "model2= CategoricalNB()\n",
    "\n",
    "pipeline = Pipeline([('over', over), ('under', under), ('model2', model2)])\n",
    "\n",
    "\n",
    "pipeline.fit(X_train, y_train) \n",
    "\n",
    "y_hat = pipeline.predict(X_test)\n",
    "print(classification_report_imbalanced(y_test, y_hat)) \n",
    "print(confusion_matrix(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f010dd12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
